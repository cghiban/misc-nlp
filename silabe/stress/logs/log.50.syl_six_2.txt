CRFSuite 0.12  Copyright (c) 2007-2011 Naoaki Okazaki

Start time of the training: 2013-06-12T17:21:13Z

Reading the data set(s)
[1] stress_syl_2.txt
0....1....2....3....4....5....6....7....8....9....10
Number of instances: 262728
Seconds required: 18.280

Statistics the data set(s)
Number of data sets (groups): 3
Number of instances: 262715
Number of items: 2615262
Number of attributes: 3169
Number of labels: 2

===== Cross validation (1/3) =====
Holdout group: 1

Feature generation
type: CRF1d
feature.minfreq: 0.000000
feature.possible_states: 0
feature.possible_transitions: 0
0....1....2....3....4....5....6....7....8....9....10
Number of features: 4377
Seconds required: 2.890

Averaged perceptron
max_iterations: 50
epsilon: 0.000000

***** Iteration #1 *****
Loss: 9964.762597
Feature norm: 224.215709
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779916, 799199, 790049) (0.9759, 0.9872, 0.9815)
    1: (61964, 72097, 81247) (0.8595, 0.7627, 0.8082)
Macro-average precision, recall, F1: (0.917663, 0.874918, 0.894830)
Item accuracy: 841880 / 871296 (0.9662)
Instance accuracy: 61808 / 87572 (0.7058)

***** Iteration #2 *****
Loss: 9745.126830
Feature norm: 262.617226
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779826, 798922, 790049) (0.9761, 0.9871, 0.9815)
    1: (62151, 72374, 81247) (0.8587, 0.7650, 0.8091)
Macro-average precision, recall, F1: (0.917423, 0.876012, 0.895348)
Item accuracy: 841977 / 871296 (0.9664)
Instance accuracy: 61957 / 87572 (0.7075)

***** Iteration #3 *****
Loss: 9723.494501
Feature norm: 286.239547
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779905, 798971, 790049) (0.9761, 0.9872, 0.9816)
    1: (62181, 72325, 81247) (0.8597, 0.7653, 0.8098)
Macro-average precision, recall, F1: (0.917941, 0.876247, 0.895707)
Item accuracy: 842086 / 871296 (0.9665)
Instance accuracy: 62080 / 87572 (0.7089)

***** Iteration #4 *****
Loss: 9686.194094
Feature norm: 303.994456
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779903, 798944, 790049) (0.9762, 0.9872, 0.9816)
    1: (62206, 72352, 81247) (0.8598, 0.7656, 0.8100)
Macro-average precision, recall, F1: (0.917968, 0.876399, 0.895805)
Item accuracy: 842109 / 871296 (0.9665)
Instance accuracy: 62089 / 87572 (0.7090)

***** Iteration #5 *****
Loss: 9670.825102
Feature norm: 318.055195
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779912, 798908, 790049) (0.9762, 0.9872, 0.9817)
    1: (62251, 72388, 81247) (0.8600, 0.7662, 0.8104)
Macro-average precision, recall, F1: (0.918093, 0.876682, 0.896020)
Item accuracy: 842163 / 871296 (0.9666)
Instance accuracy: 62125 / 87572 (0.7094)

***** Iteration #6 *****
Loss: 9701.888594
Feature norm: 329.612008
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779881, 798918, 790049) (0.9762, 0.9871, 0.9816)
    1: (62210, 72378, 81247) (0.8595, 0.7657, 0.8099)
Macro-average precision, recall, F1: (0.917843, 0.876410, 0.895757)
Item accuracy: 842091 / 871296 (0.9665)
Instance accuracy: 62072 / 87572 (0.7088)

***** Iteration #7 *****
Loss: 9707.905918
Feature norm: 339.580313
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779929, 798952, 790049) (0.9762, 0.9872, 0.9817)
    1: (62224, 72344, 81247) (0.8601, 0.7659, 0.8103)
Macro-average precision, recall, F1: (0.918151, 0.876526, 0.895958)
Item accuracy: 842153 / 871296 (0.9666)
Instance accuracy: 62122 / 87572 (0.7094)

***** Iteration #8 *****
Loss: 9644.192351
Feature norm: 348.676354
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779886, 798925, 790049) (0.9762, 0.9871, 0.9816)
    1: (62208, 72371, 81247) (0.8596, 0.7657, 0.8099)
Macro-average precision, recall, F1: (0.917870, 0.876401, 0.895764)
Item accuracy: 842094 / 871296 (0.9665)
Instance accuracy: 62097 / 87572 (0.7091)

***** Iteration #9 *****
Loss: 9689.680736
Feature norm: 356.669558
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779873, 798885, 790049) (0.9762, 0.9871, 0.9816)
    1: (62235, 72411, 81247) (0.8595, 0.7660, 0.8100)
Macro-average precision, recall, F1: (0.917835, 0.876559, 0.895838)
Item accuracy: 842108 / 871296 (0.9665)
Instance accuracy: 62104 / 87572 (0.7092)

***** Iteration #10 *****
Loss: 9667.450325
Feature norm: 363.955755
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779859, 798859, 790049) (0.9762, 0.9871, 0.9816)
    1: (62247, 72437, 81247) (0.8593, 0.7661, 0.8101)
Macro-average precision, recall, F1: (0.917771, 0.876624, 0.895847)
Item accuracy: 842106 / 871296 (0.9665)
Instance accuracy: 62101 / 87572 (0.7091)

***** Iteration #11 *****
Loss: 9667.572412
Feature norm: 370.646569
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779869, 798880, 790049) (0.9762, 0.9871, 0.9816)
    1: (62236, 72416, 81247) (0.8594, 0.7660, 0.8100)
Macro-average precision, recall, F1: (0.917813, 0.876562, 0.895830)
Item accuracy: 842105 / 871296 (0.9665)
Instance accuracy: 62096 / 87572 (0.7091)

***** Iteration #12 *****
Loss: 9659.690274
Feature norm: 376.724100
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779867, 798869, 790049) (0.9762, 0.9871, 0.9816)
    1: (62245, 72427, 81247) (0.8594, 0.7661, 0.8101)
Macro-average precision, recall, F1: (0.917815, 0.876616, 0.895862)
Item accuracy: 842112 / 871296 (0.9665)
Instance accuracy: 62103 / 87572 (0.7092)

***** Iteration #13 *****
Loss: 9675.706719
Feature norm: 382.588014
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779847, 798852, 790049) (0.9762, 0.9871, 0.9816)
    1: (62242, 72444, 81247) (0.8592, 0.7661, 0.8100)
Macro-average precision, recall, F1: (0.917692, 0.876585, 0.895790)
Item accuracy: 842089 / 871296 (0.9665)
Instance accuracy: 62094 / 87572 (0.7091)

***** Iteration #14 *****
Loss: 9679.397635
Feature norm: 388.097572
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779872, 798882, 790049) (0.9762, 0.9871, 0.9816)
    1: (62237, 72414, 81247) (0.8595, 0.7660, 0.8101)
Macro-average precision, recall, F1: (0.917833, 0.876570, 0.895843)
Item accuracy: 842109 / 871296 (0.9665)
Instance accuracy: 62110 / 87572 (0.7092)

***** Iteration #15 *****
Loss: 9677.290841
Feature norm: 393.196385
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779880, 798896, 790049) (0.9762, 0.9871, 0.9816)
    1: (62231, 72400, 81247) (0.8595, 0.7659, 0.8101)
Macro-average precision, recall, F1: (0.917871, 0.876538, 0.895842)
Item accuracy: 842111 / 871296 (0.9665)
Instance accuracy: 62121 / 87572 (0.7094)

***** Iteration #16 *****
Loss: 9642.920954
Feature norm: 397.873166
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779869, 798887, 790049) (0.9762, 0.9871, 0.9816)
    1: (62229, 72409, 81247) (0.8594, 0.7659, 0.8100)
Macro-average precision, recall, F1: (0.917802, 0.876519, 0.895801)
Item accuracy: 842098 / 871296 (0.9665)
Instance accuracy: 62113 / 87572 (0.7093)

***** Iteration #17 *****
Loss: 9663.800674
Feature norm: 402.332680
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779878, 798891, 790049) (0.9762, 0.9871, 0.9816)
    1: (62234, 72405, 81247) (0.8595, 0.7660, 0.8101)
Macro-average precision, recall, F1: (0.917864, 0.876556, 0.895849)
Item accuracy: 842112 / 871296 (0.9665)
Instance accuracy: 62128 / 87572 (0.7095)

***** Iteration #18 *****
Loss: 9693.650602
Feature norm: 406.540063
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779880, 798907, 790049) (0.9762, 0.9871, 0.9816)
    1: (62220, 72389, 81247) (0.8595, 0.7658, 0.8100)
Macro-average precision, recall, F1: (0.917853, 0.876471, 0.895796)
Item accuracy: 842100 / 871296 (0.9665)
Instance accuracy: 62110 / 87572 (0.7092)

***** Iteration #19 *****
Loss: 9646.480062
Feature norm: 410.607507
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779876, 798908, 790049) (0.9762, 0.9871, 0.9816)
    1: (62215, 72388, 81247) (0.8595, 0.7658, 0.8099)
Macro-average precision, recall, F1: (0.917822, 0.876437, 0.895763)
Item accuracy: 842091 / 871296 (0.9665)
Instance accuracy: 62104 / 87572 (0.7092)

***** Iteration #20 *****
Loss: 9651.579272
Feature norm: 414.427275
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779907, 798943, 790049) (0.9762, 0.9872, 0.9816)
    1: (62211, 72353, 81247) (0.8598, 0.7657, 0.8100)
Macro-average precision, recall, F1: (0.918000, 0.876432, 0.895838)
Item accuracy: 842118 / 871296 (0.9665)
Instance accuracy: 62123 / 87572 (0.7094)

***** Iteration #21 *****
Loss: 9671.292303
Feature norm: 418.224917
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779925, 798951, 790049) (0.9762, 0.9872, 0.9817)
    1: (62221, 72345, 81247) (0.8601, 0.7658, 0.8102)
Macro-average precision, recall, F1: (0.918123, 0.876505, 0.895933)
Item accuracy: 842146 / 871296 (0.9665)
Instance accuracy: 62143 / 87572 (0.7096)

***** Iteration #22 *****
Loss: 9693.459177
Feature norm: 421.802713
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779915, 798924, 790049) (0.9762, 0.9872, 0.9817)
    1: (62238, 72372, 81247) (0.8600, 0.7660, 0.8103)
Macro-average precision, recall, F1: (0.918090, 0.876604, 0.895975)
Item accuracy: 842153 / 871296 (0.9666)
Instance accuracy: 62146 / 87572 (0.7097)

***** Iteration #23 *****
Loss: 9644.243899
Feature norm: 425.221640
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779888, 798908, 790049) (0.9762, 0.9871, 0.9816)
    1: (62227, 72388, 81247) (0.8596, 0.7659, 0.8101)
Macro-average precision, recall, F1: (0.917912, 0.876519, 0.895849)
Item accuracy: 842115 / 871296 (0.9665)
Instance accuracy: 62106 / 87572 (0.7092)

***** Iteration #24 *****
Loss: 9665.681815
Feature norm: 428.508171
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779888, 798913, 790049) (0.9762, 0.9871, 0.9816)
    1: (62222, 72383, 81247) (0.8596, 0.7658, 0.8100)
Macro-average precision, recall, F1: (0.917904, 0.876488, 0.895828)
Item accuracy: 842110 / 871296 (0.9665)
Instance accuracy: 62106 / 87572 (0.7092)

***** Iteration #25 *****
Loss: 9657.352714
Feature norm: 431.668069
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779906, 798936, 790049) (0.9762, 0.9872, 0.9816)
    1: (62217, 72360, 81247) (0.8598, 0.7658, 0.8101)
Macro-average precision, recall, F1: (0.918003, 0.876469, 0.895860)
Item accuracy: 842123 / 871296 (0.9665)
Instance accuracy: 62117 / 87572 (0.7093)

***** Iteration #26 *****
Loss: 9641.353972
Feature norm: 434.635370
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779895, 798920, 790049) (0.9762, 0.9871, 0.9816)
    1: (62222, 72376, 81247) (0.8597, 0.7658, 0.8101)
Macro-average precision, recall, F1: (0.917946, 0.876493, 0.895849)
Item accuracy: 842117 / 871296 (0.9665)
Instance accuracy: 62119 / 87572 (0.7093)

***** Iteration #27 *****
Loss: 9643.314709
Feature norm: 437.568187
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779895, 798924, 790049) (0.9762, 0.9871, 0.9816)
    1: (62218, 72372, 81247) (0.8597, 0.7658, 0.8100)
Macro-average precision, recall, F1: (0.917939, 0.876468, 0.895832)
Item accuracy: 842113 / 871296 (0.9665)
Instance accuracy: 62111 / 87572 (0.7093)

***** Iteration #28 *****
Loss: 9677.155312
Feature norm: 440.463926
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779895, 798923, 790049) (0.9762, 0.9871, 0.9816)
    1: (62219, 72373, 81247) (0.8597, 0.7658, 0.8100)
Macro-average precision, recall, F1: (0.917941, 0.876474, 0.895836)
Item accuracy: 842114 / 871296 (0.9665)
Instance accuracy: 62115 / 87572 (0.7093)

***** Iteration #29 *****
Loss: 9682.703815
Feature norm: 443.256590
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779890, 798925, 790049) (0.9762, 0.9871, 0.9816)
    1: (62212, 72371, 81247) (0.8596, 0.7657, 0.8100)
Macro-average precision, recall, F1: (0.917900, 0.876428, 0.895792)
Item accuracy: 842102 / 871296 (0.9665)
Instance accuracy: 62101 / 87572 (0.7091)

***** Iteration #30 *****
Loss: 9638.249127
Feature norm: 445.961346
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779881, 798899, 790049) (0.9762, 0.9871, 0.9816)
    1: (62229, 72397, 81247) (0.8596, 0.7659, 0.8100)
Macro-average precision, recall, F1: (0.917873, 0.876527, 0.895837)
Item accuracy: 842110 / 871296 (0.9665)
Instance accuracy: 62108 / 87572 (0.7092)

***** Iteration #31 *****
Loss: 9682.346499
Feature norm: 448.584970
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779892, 798909, 790049) (0.9762, 0.9871, 0.9816)
    1: (62230, 72387, 81247) (0.8597, 0.7659, 0.8101)
Macro-average precision, recall, F1: (0.917941, 0.876540, 0.895873)
Item accuracy: 842122 / 871296 (0.9665)
Instance accuracy: 62118 / 87572 (0.7093)

***** Iteration #32 *****
Loss: 9678.927385
Feature norm: 451.154113
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779872, 798902, 790049) (0.9762, 0.9871, 0.9816)
    1: (62217, 72394, 81247) (0.8594, 0.7658, 0.8099)
Macro-average precision, recall, F1: (0.917801, 0.876447, 0.895760)
Item accuracy: 842089 / 871296 (0.9665)
Instance accuracy: 62095 / 87572 (0.7091)

***** Iteration #33 *****
Loss: 9658.780207
Feature norm: 453.622426
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779864, 798875, 790049) (0.9762, 0.9871, 0.9816)
    1: (62236, 72421, 81247) (0.8594, 0.7660, 0.8100)
Macro-average precision, recall, F1: (0.917783, 0.876559, 0.895816)
Item accuracy: 842100 / 871296 (0.9665)
Instance accuracy: 62109 / 87572 (0.7092)

***** Iteration #34 *****
Loss: 9661.855989
Feature norm: 455.975822
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779882, 798896, 790049) (0.9762, 0.9871, 0.9816)
    1: (62233, 72400, 81247) (0.8596, 0.7660, 0.8101)
Macro-average precision, recall, F1: (0.917886, 0.876552, 0.895856)
Item accuracy: 842115 / 871296 (0.9665)
Instance accuracy: 62116 / 87572 (0.7093)

***** Iteration #35 *****
Loss: 9671.814273
Feature norm: 458.330443
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779883, 798903, 790049) (0.9762, 0.9871, 0.9816)
    1: (62227, 72393, 81247) (0.8596, 0.7659, 0.8100)
Macro-average precision, recall, F1: (0.917882, 0.876516, 0.895834)
Item accuracy: 842110 / 871296 (0.9665)
Instance accuracy: 62110 / 87572 (0.7092)

***** Iteration #36 *****
Loss: 9660.389128
Feature norm: 460.645290
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779895, 798915, 790049) (0.9762, 0.9871, 0.9816)
    1: (62227, 72381, 81247) (0.8597, 0.7659, 0.8101)
Macro-average precision, recall, F1: (0.917954, 0.876523, 0.895870)
Item accuracy: 842122 / 871296 (0.9665)
Instance accuracy: 62120 / 87572 (0.7094)

***** Iteration #37 *****
Loss: 9662.354097
Feature norm: 462.860794
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779889, 798907, 790049) (0.9762, 0.9871, 0.9816)
    1: (62229, 72389, 81247) (0.8596, 0.7659, 0.8101)
Macro-average precision, recall, F1: (0.917921, 0.876532, 0.895860)
Item accuracy: 842118 / 871296 (0.9665)
Instance accuracy: 62119 / 87572 (0.7093)

***** Iteration #38 *****
Loss: 9655.470893
Feature norm: 465.061393
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779880, 798888, 790049) (0.9762, 0.9871, 0.9816)
    1: (62239, 72408, 81247) (0.8596, 0.7660, 0.8101)
Macro-average precision, recall, F1: (0.917883, 0.876588, 0.895875)
Item accuracy: 842119 / 871296 (0.9665)
Instance accuracy: 62119 / 87572 (0.7093)

***** Iteration #39 *****
Loss: 9686.765055
Feature norm: 467.198539
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779877, 798881, 790049) (0.9762, 0.9871, 0.9816)
    1: (62243, 72415, 81247) (0.8595, 0.7661, 0.8101)
Macro-average precision, recall, F1: (0.917872, 0.876610, 0.895883)
Item accuracy: 842120 / 871296 (0.9665)
Instance accuracy: 62125 / 87572 (0.7094)

***** Iteration #40 *****
Loss: 9671.996648
Feature norm: 469.310059
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779866, 798867, 790049) (0.9762, 0.9871, 0.9816)
    1: (62246, 72429, 81247) (0.8594, 0.7661, 0.8101)
Macro-average precision, recall, F1: (0.917811, 0.876622, 0.895863)
Item accuracy: 842112 / 871296 (0.9665)
Instance accuracy: 62122 / 87572 (0.7094)

***** Iteration #41 *****
Loss: 9649.131728
Feature norm: 471.368231
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779852, 798852, 790049) (0.9762, 0.9871, 0.9816)
    1: (62247, 72444, 81247) (0.8592, 0.7661, 0.8100)
Macro-average precision, recall, F1: (0.917729, 0.876619, 0.895826)
Item accuracy: 842099 / 871296 (0.9665)
Instance accuracy: 62111 / 87572 (0.7093)

***** Iteration #42 *****
Loss: 9667.393967
Feature norm: 473.399937
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779852, 798850, 790049) (0.9762, 0.9871, 0.9816)
    1: (62249, 72446, 81247) (0.8592, 0.7662, 0.8100)
Macro-average precision, recall, F1: (0.917733, 0.876632, 0.895835)
Item accuracy: 842101 / 871296 (0.9665)
Instance accuracy: 62117 / 87572 (0.7093)

***** Iteration #43 *****
Loss: 9685.284057
Feature norm: 475.339025
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779845, 798840, 790049) (0.9762, 0.9871, 0.9816)
    1: (62252, 72456, 81247) (0.8592, 0.7662, 0.8100)
Macro-average precision, recall, F1: (0.917696, 0.876646, 0.895826)
Item accuracy: 842097 / 871296 (0.9665)
Instance accuracy: 62114 / 87572 (0.7093)

***** Iteration #44 *****
Loss: 9671.970016
Feature norm: 477.227286
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779854, 798854, 790049) (0.9762, 0.9871, 0.9816)
    1: (62247, 72442, 81247) (0.8593, 0.7661, 0.8100)
Macro-average precision, recall, F1: (0.917741, 0.876620, 0.895832)
Item accuracy: 842101 / 871296 (0.9665)
Instance accuracy: 62115 / 87572 (0.7093)

***** Iteration #45 *****
Loss: 9650.134717
Feature norm: 479.098698
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779858, 798860, 790049) (0.9762, 0.9871, 0.9816)
    1: (62245, 72436, 81247) (0.8593, 0.7661, 0.8100)
Macro-average precision, recall, F1: (0.917762, 0.876611, 0.895836)
Item accuracy: 842103 / 871296 (0.9665)
Instance accuracy: 62114 / 87572 (0.7093)

***** Iteration #46 *****
Loss: 9684.269838
Feature norm: 480.966175
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779860, 798856, 790049) (0.9762, 0.9871, 0.9816)
    1: (62251, 72440, 81247) (0.8593, 0.7662, 0.8101)
Macro-average precision, recall, F1: (0.917783, 0.876649, 0.895867)
Item accuracy: 842111 / 871296 (0.9665)
Instance accuracy: 62124 / 87572 (0.7094)

***** Iteration #47 *****
Loss: 9659.951145
Feature norm: 482.762263
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779853, 798856, 790049) (0.9762, 0.9871, 0.9816)
    1: (62244, 72440, 81247) (0.8592, 0.7661, 0.8100)
Macro-average precision, recall, F1: (0.917731, 0.876601, 0.895817)
Item accuracy: 842097 / 871296 (0.9665)
Instance accuracy: 62116 / 87572 (0.7093)

***** Iteration #48 *****
Loss: 9647.124325
Feature norm: 484.512781
Seconds required for this iteration: 0.780
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779863, 798862, 790049) (0.9762, 0.9871, 0.9816)
    1: (62248, 72434, 81247) (0.8594, 0.7662, 0.8101)
Macro-average precision, recall, F1: (0.917796, 0.876632, 0.895863)
Item accuracy: 842111 / 871296 (0.9665)
Instance accuracy: 62125 / 87572 (0.7094)

***** Iteration #49 *****
Loss: 9679.196298
Feature norm: 486.281784
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779855, 798857, 790049) (0.9762, 0.9871, 0.9816)
    1: (62245, 72439, 81247) (0.8593, 0.7661, 0.8100)
Macro-average precision, recall, F1: (0.917744, 0.876609, 0.895827)
Item accuracy: 842100 / 871296 (0.9665)
Instance accuracy: 62117 / 87572 (0.7093)

***** Iteration #50 *****
Loss: 9666.423465
Feature norm: 487.997912
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779856, 798858, 790049) (0.9762, 0.9871, 0.9816)
    1: (62245, 72438, 81247) (0.8593, 0.7661, 0.8100)
Macro-average precision, recall, F1: (0.917750, 0.876609, 0.895830)
Item accuracy: 842101 / 871296 (0.9665)
Instance accuracy: 62116 / 87572 (0.7093)

Total seconds required for training: 51.600


===== Cross validation (2/3) =====
Holdout group: 2

Feature generation
type: CRF1d
feature.minfreq: 0.000000
feature.possible_states: 0
feature.possible_transitions: 0
0....1....2....3....4....5....6....7....8....9....10
Number of features: 4387
Seconds required: 2.830

Averaged perceptron
max_iterations: 50
epsilon: 0.000000

***** Iteration #1 *****
Loss: 9973.842297
Feature norm: 222.846701
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (781004, 800426, 790868) (0.9757, 0.9875, 0.9816)
    1: (61849, 71713, 81271) (0.8625, 0.7610, 0.8086)
Macro-average precision, recall, F1: (0.919094, 0.874275, 0.895082)
Item accuracy: 842853 / 872139 (0.9664)
Instance accuracy: 61878 / 87572 (0.7066)

***** Iteration #2 *****
Loss: 9759.743476
Feature norm: 260.237503
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780938, 800173, 790868) (0.9760, 0.9874, 0.9817)
    1: (62036, 71966, 81271) (0.8620, 0.7633, 0.8097)
Macro-average precision, recall, F1: (0.918990, 0.875383, 0.895672)
Item accuracy: 842974 / 872139 (0.9666)
Instance accuracy: 62004 / 87572 (0.7080)

***** Iteration #3 *****
Loss: 9748.229808
Feature norm: 284.601112
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780931, 800136, 790868) (0.9760, 0.9874, 0.9817)
    1: (62066, 72003, 81271) (0.8620, 0.7637, 0.8099)
Macro-average precision, recall, F1: (0.918995, 0.875564, 0.895777)
Item accuracy: 842997 / 872139 (0.9666)
Instance accuracy: 62035 / 87572 (0.7084)

***** Iteration #4 *****
Loss: 9757.418408
Feature norm: 302.965834
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780921, 800075, 790868) (0.9761, 0.9874, 0.9817)
    1: (62117, 72064, 81271) (0.8620, 0.7643, 0.8102)
Macro-average precision, recall, F1: (0.919015, 0.875871, 0.895961)
Item accuracy: 843038 / 872139 (0.9666)
Instance accuracy: 62089 / 87572 (0.7090)

***** Iteration #5 *****
Loss: 9728.348429
Feature norm: 317.199599
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780910, 800080, 790868) (0.9760, 0.9874, 0.9817)
    1: (62101, 72059, 81271) (0.8618, 0.7641, 0.8100)
Macro-average precision, recall, F1: (0.918924, 0.875766, 0.895861)
Item accuracy: 843011 / 872139 (0.9666)
Instance accuracy: 62060 / 87572 (0.7087)

***** Iteration #6 *****
Loss: 9694.223853
Feature norm: 329.040528
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780905, 800075, 790868) (0.9760, 0.9874, 0.9817)
    1: (62101, 72064, 81271) (0.8617, 0.7641, 0.8100)
Macro-average precision, recall, F1: (0.918894, 0.875762, 0.895846)
Item accuracy: 843006 / 872139 (0.9666)
Instance accuracy: 62046 / 87572 (0.7085)

***** Iteration #7 *****
Loss: 9682.876480
Feature norm: 339.285879
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780912, 800038, 790868) (0.9761, 0.9874, 0.9817)
    1: (62145, 72101, 81271) (0.8619, 0.7647, 0.8104)
Macro-average precision, recall, F1: (0.919005, 0.876038, 0.896051)
Item accuracy: 843057 / 872139 (0.9667)
Instance accuracy: 62093 / 87572 (0.7091)

***** Iteration #8 *****
Loss: 9685.174006
Feature norm: 348.380020
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780903, 800050, 790868) (0.9761, 0.9874, 0.9817)
    1: (62124, 72089, 81271) (0.8618, 0.7644, 0.8102)
Macro-average precision, recall, F1: (0.918918, 0.875903, 0.895937)
Item accuracy: 843027 / 872139 (0.9666)
Instance accuracy: 62071 / 87572 (0.7088)

***** Iteration #9 *****
Loss: 9710.499220
Feature norm: 356.212767
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780932, 800080, 790868) (0.9761, 0.9874, 0.9817)
    1: (62123, 72059, 81271) (0.8621, 0.7644, 0.8103)
Macro-average precision, recall, F1: (0.919090, 0.875915, 0.896018)
Item accuracy: 843055 / 872139 (0.9667)
Instance accuracy: 62079 / 87572 (0.7089)

***** Iteration #10 *****
Loss: 9698.605279
Feature norm: 363.484540
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780907, 800064, 790868) (0.9761, 0.9874, 0.9817)
    1: (62114, 72075, 81271) (0.8618, 0.7643, 0.8101)
Macro-average precision, recall, F1: (0.918926, 0.875844, 0.895907)
Item accuracy: 843021 / 872139 (0.9666)
Instance accuracy: 62056 / 87572 (0.7086)

***** Iteration #11 *****
Loss: 9682.421939
Feature norm: 370.275744
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780908, 800057, 790868) (0.9761, 0.9874, 0.9817)
    1: (62122, 72082, 81271) (0.8618, 0.7644, 0.8102)
Macro-average precision, recall, F1: (0.918945, 0.875894, 0.895943)
Item accuracy: 843030 / 872139 (0.9666)
Instance accuracy: 62074 / 87572 (0.7088)

***** Iteration #12 *****
Loss: 9671.240767
Feature norm: 376.516516
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780880, 800022, 790868) (0.9761, 0.9874, 0.9817)
    1: (62129, 72117, 81271) (0.8615, 0.7645, 0.8101)
Macro-average precision, recall, F1: (0.918788, 0.875919, 0.895889)
Item accuracy: 843009 / 872139 (0.9666)
Instance accuracy: 62057 / 87572 (0.7086)

***** Iteration #13 *****
Loss: 9653.125480
Feature norm: 382.296927
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780902, 800029, 790868) (0.9761, 0.9874, 0.9817)
    1: (62144, 72110, 81271) (0.8618, 0.7647, 0.8103)
Macro-average precision, recall, F1: (0.918943, 0.876025, 0.896017)
Item accuracy: 843046 / 872139 (0.9666)
Instance accuracy: 62090 / 87572 (0.7090)

***** Iteration #14 *****
Loss: 9658.208342
Feature norm: 387.533710
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780899, 800025, 790868) (0.9761, 0.9874, 0.9817)
    1: (62145, 72114, 81271) (0.8618, 0.7647, 0.8103)
Macro-average precision, recall, F1: (0.918927, 0.876029, 0.896013)
Item accuracy: 843044 / 872139 (0.9666)
Instance accuracy: 62086 / 87572 (0.7090)

***** Iteration #15 *****
Loss: 9710.693718
Feature norm: 392.542690
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780903, 800028, 790868) (0.9761, 0.9874, 0.9817)
    1: (62146, 72111, 81271) (0.8618, 0.7647, 0.8103)
Macro-average precision, recall, F1: (0.918952, 0.876038, 0.896029)
Item accuracy: 843049 / 872139 (0.9666)
Instance accuracy: 62089 / 87572 (0.7090)

***** Iteration #16 *****
Loss: 9700.276737
Feature norm: 397.240251
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780901, 800034, 790868) (0.9761, 0.9874, 0.9817)
    1: (62138, 72105, 81271) (0.8618, 0.7646, 0.8103)
Macro-average precision, recall, F1: (0.918928, 0.875988, 0.895989)
Item accuracy: 843039 / 872139 (0.9666)
Instance accuracy: 62076 / 87572 (0.7089)

***** Iteration #17 *****
Loss: 9671.011796
Feature norm: 401.578471
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780877, 799991, 790868) (0.9761, 0.9874, 0.9817)
    1: (62157, 72148, 81271) (0.8615, 0.7648, 0.8103)
Macro-average precision, recall, F1: (0.918814, 0.876089, 0.895998)
Item accuracy: 843034 / 872139 (0.9666)
Instance accuracy: 62074 / 87572 (0.7088)

***** Iteration #18 *****
Loss: 9672.967869
Feature norm: 405.617178
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780921, 800028, 790868) (0.9761, 0.9874, 0.9817)
    1: (62164, 72111, 81271) (0.8621, 0.7649, 0.8106)
Macro-average precision, recall, F1: (0.919088, 0.876160, 0.896157)
Item accuracy: 843085 / 872139 (0.9667)
Instance accuracy: 62119 / 87572 (0.7093)

***** Iteration #19 *****
Loss: 9753.781030
Feature norm: 409.558751
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780934, 800062, 790868) (0.9761, 0.9874, 0.9817)
    1: (62143, 72077, 81271) (0.8622, 0.7646, 0.8105)
Macro-average precision, recall, F1: (0.919134, 0.876039, 0.896108)
Item accuracy: 843077 / 872139 (0.9667)
Instance accuracy: 62111 / 87572 (0.7093)

***** Iteration #20 *****
Loss: 9691.301018
Feature norm: 413.259217
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780926, 800047, 790868) (0.9761, 0.9874, 0.9817)
    1: (62150, 72092, 81271) (0.8621, 0.7647, 0.8105)
Macro-average precision, recall, F1: (0.919097, 0.876077, 0.896114)
Item accuracy: 843076 / 872139 (0.9667)
Instance accuracy: 62112 / 87572 (0.7093)

***** Iteration #21 *****
Loss: 9679.663882
Feature norm: 416.887524
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780911, 800039, 790868) (0.9761, 0.9874, 0.9817)
    1: (62143, 72100, 81271) (0.8619, 0.7646, 0.8104)
Macro-average precision, recall, F1: (0.918996, 0.876025, 0.896040)
Item accuracy: 843054 / 872139 (0.9667)
Instance accuracy: 62095 / 87572 (0.7091)

***** Iteration #22 *****
Loss: 9702.645693
Feature norm: 420.398589
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780909, 800023, 790868) (0.9761, 0.9874, 0.9817)
    1: (62157, 72116, 81271) (0.8619, 0.7648, 0.8105)
Macro-average precision, recall, F1: (0.919006, 0.876110, 0.896093)
Item accuracy: 843066 / 872139 (0.9667)
Instance accuracy: 62112 / 87572 (0.7093)

***** Iteration #23 *****
Loss: 9689.719255
Feature norm: 423.766429
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780925, 800051, 790868) (0.9761, 0.9874, 0.9817)
    1: (62145, 72088, 81271) (0.8621, 0.7647, 0.8105)
Macro-average precision, recall, F1: (0.919083, 0.876046, 0.896090)
Item accuracy: 843070 / 872139 (0.9667)
Instance accuracy: 62118 / 87572 (0.7093)

***** Iteration #24 *****
Loss: 9684.609323
Feature norm: 427.015352
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780904, 800009, 790868) (0.9761, 0.9874, 0.9817)
    1: (62166, 72130, 81271) (0.8619, 0.7649, 0.8105)
Macro-average precision, recall, F1: (0.918990, 0.876162, 0.896115)
Item accuracy: 843070 / 872139 (0.9667)
Instance accuracy: 62124 / 87572 (0.7094)

***** Iteration #25 *****
Loss: 9674.750083
Feature norm: 430.194874
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780890, 799977, 790868) (0.9761, 0.9874, 0.9817)
    1: (62184, 72162, 81271) (0.8617, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.918934, 0.876264, 0.896149)
Item accuracy: 843074 / 872139 (0.9667)
Instance accuracy: 62128 / 87572 (0.7095)

***** Iteration #26 *****
Loss: 9678.636671
Feature norm: 433.209444
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780885, 799968, 790868) (0.9761, 0.9874, 0.9817)
    1: (62188, 72171, 81271) (0.8617, 0.7652, 0.8106)
Macro-average precision, recall, F1: (0.918911, 0.876285, 0.896151)
Item accuracy: 843073 / 872139 (0.9667)
Instance accuracy: 62132 / 87572 (0.7095)

***** Iteration #27 *****
Loss: 9708.689986
Feature norm: 436.132323
Seconds required for this iteration: 0.880
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780913, 800028, 790868) (0.9761, 0.9874, 0.9817)
    1: (62156, 72111, 81271) (0.8619, 0.7648, 0.8105)
Macro-average precision, recall, F1: (0.919028, 0.876106, 0.896100)
Item accuracy: 843069 / 872139 (0.9667)
Instance accuracy: 62123 / 87572 (0.7094)

***** Iteration #28 *****
Loss: 9715.983548
Feature norm: 438.981988
Seconds required for this iteration: 0.870
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780909, 800021, 790868) (0.9761, 0.9874, 0.9817)
    1: (62159, 72118, 81271) (0.8619, 0.7648, 0.8105)
Macro-average precision, recall, F1: (0.919009, 0.876122, 0.896101)
Item accuracy: 843068 / 872139 (0.9667)
Instance accuracy: 62129 / 87572 (0.7095)

***** Iteration #29 *****
Loss: 9668.173372
Feature norm: 441.759895
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780910, 800033, 790868) (0.9761, 0.9874, 0.9817)
    1: (62148, 72106, 81271) (0.8619, 0.7647, 0.8104)
Macro-average precision, recall, F1: (0.918997, 0.876055, 0.896058)
Item accuracy: 843058 / 872139 (0.9667)
Instance accuracy: 62117 / 87572 (0.7093)

***** Iteration #30 *****
Loss: 9717.640979
Feature norm: 444.495851
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780913, 800040, 790868) (0.9761, 0.9874, 0.9817)
    1: (62144, 72099, 81271) (0.8619, 0.7647, 0.8104)
Macro-average precision, recall, F1: (0.919009, 0.876032, 0.896050)
Item accuracy: 843057 / 872139 (0.9667)
Instance accuracy: 62116 / 87572 (0.7093)

***** Iteration #31 *****
Loss: 9689.538244
Feature norm: 447.059123
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780914, 800021, 790868) (0.9761, 0.9874, 0.9817)
    1: (62164, 72118, 81271) (0.8620, 0.7649, 0.8105)
Macro-average precision, recall, F1: (0.919047, 0.876156, 0.896137)
Item accuracy: 843078 / 872139 (0.9667)
Instance accuracy: 62133 / 87572 (0.7095)

***** Iteration #32 *****
Loss: 9680.885401
Feature norm: 449.566161
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780899, 800003, 790868) (0.9761, 0.9874, 0.9817)
    1: (62167, 72136, 81271) (0.8618, 0.7649, 0.8105)
Macro-average precision, recall, F1: (0.918961, 0.876165, 0.896105)
Item accuracy: 843066 / 872139 (0.9667)
Instance accuracy: 62126 / 87572 (0.7094)

***** Iteration #33 *****
Loss: 9673.188338
Feature norm: 451.991803
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780893, 800003, 790868) (0.9761, 0.9874, 0.9817)
    1: (62161, 72136, 81271) (0.8617, 0.7649, 0.8104)
Macro-average precision, recall, F1: (0.918916, 0.876124, 0.896062)
Item accuracy: 843054 / 872139 (0.9667)
Instance accuracy: 62115 / 87572 (0.7093)

***** Iteration #34 *****
Loss: 9694.314226
Feature norm: 454.344255
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780898, 799996, 790868) (0.9761, 0.9874, 0.9817)
    1: (62173, 72143, 81271) (0.8618, 0.7650, 0.8105)
Macro-average precision, recall, F1: (0.918965, 0.876201, 0.896127)
Item accuracy: 843071 / 872139 (0.9667)
Instance accuracy: 62132 / 87572 (0.7095)

***** Iteration #35 *****
Loss: 9698.516698
Feature norm: 456.657960
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780897, 799993, 790868) (0.9761, 0.9874, 0.9817)
    1: (62175, 72146, 81271) (0.8618, 0.7650, 0.8105)
Macro-average precision, recall, F1: (0.918962, 0.876213, 0.896132)
Item accuracy: 843072 / 872139 (0.9667)
Instance accuracy: 62132 / 87572 (0.7095)

***** Iteration #36 *****
Loss: 9690.322388
Feature norm: 458.886572
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780902, 799990, 790868) (0.9761, 0.9874, 0.9817)
    1: (62183, 72149, 81271) (0.8619, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.919004, 0.876265, 0.896181)
Item accuracy: 843085 / 872139 (0.9667)
Instance accuracy: 62150 / 87572 (0.7097)

***** Iteration #37 *****
Loss: 9656.838648
Feature norm: 461.123482
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780891, 799969, 790868) (0.9762, 0.9874, 0.9817)
    1: (62193, 72170, 81271) (0.8618, 0.7653, 0.8106)
Macro-average precision, recall, F1: (0.918954, 0.876320, 0.896190)
Item accuracy: 843084 / 872139 (0.9667)
Instance accuracy: 62151 / 87572 (0.7097)

***** Iteration #38 *****
Loss: 9684.445864
Feature norm: 463.342489
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780896, 799985, 790868) (0.9761, 0.9874, 0.9817)
    1: (62182, 72154, 81271) (0.8618, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.918967, 0.876255, 0.896159)
Item accuracy: 843078 / 872139 (0.9667)
Instance accuracy: 62142 / 87572 (0.7096)

***** Iteration #39 *****
Loss: 9664.044937
Feature norm: 465.449342
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780891, 799976, 790868) (0.9761, 0.9874, 0.9817)
    1: (62186, 72163, 81271) (0.8617, 0.7652, 0.8106)
Macro-average precision, recall, F1: (0.918943, 0.876277, 0.896161)
Item accuracy: 843077 / 872139 (0.9667)
Instance accuracy: 62143 / 87572 (0.7096)

***** Iteration #40 *****
Loss: 9673.988530
Feature norm: 467.581648
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780887, 799976, 790868) (0.9761, 0.9874, 0.9817)
    1: (62182, 72163, 81271) (0.8617, 0.7651, 0.8105)
Macro-average precision, recall, F1: (0.918913, 0.876249, 0.896132)
Item accuracy: 843069 / 872139 (0.9667)
Instance accuracy: 62132 / 87572 (0.7095)

***** Iteration #41 *****
Loss: 9658.871337
Feature norm: 469.654536
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780890, 799971, 790868) (0.9761, 0.9874, 0.9817)
    1: (62190, 72168, 81271) (0.8617, 0.7652, 0.8106)
Macro-average precision, recall, F1: (0.918944, 0.876301, 0.896174)
Item accuracy: 843080 / 872139 (0.9667)
Instance accuracy: 62142 / 87572 (0.7096)

***** Iteration #42 *****
Loss: 9652.818403
Feature norm: 471.644918
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780899, 799996, 790868) (0.9761, 0.9874, 0.9817)
    1: (62174, 72143, 81271) (0.8618, 0.7650, 0.8105)
Macro-average precision, recall, F1: (0.918972, 0.876208, 0.896134)
Item accuracy: 843073 / 872139 (0.9667)
Instance accuracy: 62134 / 87572 (0.7095)

***** Iteration #43 *****
Loss: 9672.063503
Feature norm: 473.608968
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780885, 799967, 790868) (0.9761, 0.9874, 0.9817)
    1: (62189, 72172, 81271) (0.8617, 0.7652, 0.8106)
Macro-average precision, recall, F1: (0.918912, 0.876291, 0.896155)
Item accuracy: 843074 / 872139 (0.9667)
Instance accuracy: 62133 / 87572 (0.7095)

***** Iteration #44 *****
Loss: 9707.054238
Feature norm: 475.499478
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780900, 799993, 790868) (0.9761, 0.9874, 0.9817)
    1: (62178, 72146, 81271) (0.8618, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.918985, 0.876233, 0.896154)
Item accuracy: 843078 / 872139 (0.9667)
Instance accuracy: 62136 / 87572 (0.7095)

***** Iteration #45 *****
Loss: 9684.053038
Feature norm: 477.359233
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780904, 799995, 790868) (0.9761, 0.9874, 0.9817)
    1: (62180, 72144, 81271) (0.8619, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.919012, 0.876248, 0.896174)
Item accuracy: 843084 / 872139 (0.9667)
Instance accuracy: 62140 / 87572 (0.7096)

***** Iteration #46 *****
Loss: 9653.024643
Feature norm: 479.188442
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780915, 800006, 790868) (0.9761, 0.9874, 0.9817)
    1: (62180, 72133, 81271) (0.8620, 0.7651, 0.8107)
Macro-average precision, recall, F1: (0.919078, 0.876255, 0.896207)
Item accuracy: 843095 / 872139 (0.9667)
Instance accuracy: 62151 / 87572 (0.7097)

***** Iteration #47 *****
Loss: 9680.050568
Feature norm: 480.990022
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780906, 800000, 790868) (0.9761, 0.9874, 0.9817)
    1: (62177, 72139, 81271) (0.8619, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.919019, 0.876231, 0.896167)
Item accuracy: 843083 / 872139 (0.9667)
Instance accuracy: 62137 / 87572 (0.7096)

***** Iteration #48 *****
Loss: 9693.162474
Feature norm: 482.808853
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780914, 800010, 790868) (0.9761, 0.9874, 0.9817)
    1: (62175, 72129, 81271) (0.8620, 0.7650, 0.8106)
Macro-average precision, recall, F1: (0.919064, 0.876223, 0.896183)
Item accuracy: 843089 / 872139 (0.9667)
Instance accuracy: 62147 / 87572 (0.7097)

***** Iteration #49 *****
Loss: 9660.942171
Feature norm: 484.587157
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780875, 799949, 790868) (0.9762, 0.9874, 0.9817)
    1: (62197, 72190, 81271) (0.8616, 0.7653, 0.8106)
Macro-average precision, recall, F1: (0.918865, 0.876334, 0.896159)
Item accuracy: 843072 / 872139 (0.9667)
Instance accuracy: 62138 / 87572 (0.7096)

***** Iteration #50 *****
Loss: 9699.544443
Feature norm: 486.348118
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780903, 799993, 790868) (0.9761, 0.9874, 0.9817)
    1: (62181, 72146, 81271) (0.8619, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.919007, 0.876253, 0.896175)
Item accuracy: 843084 / 872139 (0.9667)
Instance accuracy: 62144 / 87572 (0.7096)

Total seconds required for training: 51.820


===== Cross validation (3/3) =====
Holdout group: 3

Feature generation
type: CRF1d
feature.minfreq: 0.000000
feature.possible_states: 0
feature.possible_transitions: 0
0....1....2....3....4....5....6....7....8....9....10
Number of features: 4353
Seconds required: 2.770

Averaged perceptron
max_iterations: 50
epsilon: 0.000000

***** Iteration #1 *****
Loss: 10020.104694
Feature norm: 226.281665
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780641, 799845, 790624) (0.9760, 0.9874, 0.9816)
    1: (61999, 71982, 81203) (0.8613, 0.7635, 0.8095)
Macro-average precision, recall, F1: (0.918651, 0.875440, 0.895557)
Item accuracy: 842640 / 871827 (0.9665)
Instance accuracy: 61885 / 87571 (0.7067)

***** Iteration #2 *****
Loss: 9808.636100
Feature norm: 263.883752
Seconds required for this iteration: 0.810
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780679, 799729, 790624) (0.9762, 0.9874, 0.9818)
    1: (62153, 72098, 81203) (0.8621, 0.7654, 0.8109)
Macro-average precision, recall, F1: (0.919121, 0.876412, 0.896315)
Item accuracy: 842832 / 871827 (0.9667)
Instance accuracy: 62076 / 87571 (0.7089)

***** Iteration #3 *****
Loss: 9798.140969
Feature norm: 287.886845
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780703, 799772, 790624) (0.9762, 0.9875, 0.9818)
    1: (62134, 72055, 81203) (0.8623, 0.7652, 0.8108)
Macro-average precision, recall, F1: (0.919235, 0.876310, 0.896307)
Item accuracy: 842837 / 871827 (0.9667)
Instance accuracy: 62104 / 87571 (0.7092)

***** Iteration #4 *****
Loss: 9785.524425
Feature norm: 304.933389
Seconds required for this iteration: 0.810
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780672, 799748, 790624) (0.9761, 0.9874, 0.9817)
    1: (62127, 72079, 81203) (0.8619, 0.7651, 0.8106)
Macro-average precision, recall, F1: (0.919038, 0.876248, 0.896186)
Item accuracy: 842799 / 871827 (0.9667)
Instance accuracy: 62076 / 87571 (0.7089)

***** Iteration #5 *****
Loss: 9750.338470
Feature norm: 318.439628
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780659, 799709, 790624) (0.9762, 0.9874, 0.9818)
    1: (62153, 72118, 81203) (0.8618, 0.7654, 0.8108)
Macro-average precision, recall, F1: (0.919001, 0.876399, 0.896256)
Item accuracy: 842812 / 871827 (0.9667)
Instance accuracy: 62096 / 87571 (0.7091)

***** Iteration #6 *****
Loss: 9763.301552
Feature norm: 329.672571
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780628, 799627, 790624) (0.9762, 0.9874, 0.9818)
    1: (62204, 72200, 81203) (0.8616, 0.7660, 0.8110)
Macro-average precision, recall, F1: (0.918896, 0.876694, 0.896378)
Item accuracy: 842832 / 871827 (0.9667)
Instance accuracy: 62132 / 87571 (0.7095)

***** Iteration #7 *****
Loss: 9752.302122
Feature norm: 339.226692
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780628, 799641, 790624) (0.9762, 0.9874, 0.9818)
    1: (62190, 72186, 81203) (0.8615, 0.7659, 0.8109)
Macro-average precision, recall, F1: (0.918874, 0.876608, 0.896319)
Item accuracy: 842818 / 871827 (0.9667)
Instance accuracy: 62122 / 87571 (0.7094)

***** Iteration #8 *****
Loss: 9744.978444
Feature norm: 347.849413
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780598, 799536, 790624) (0.9763, 0.9873, 0.9818)
    1: (62265, 72291, 81203) (0.8613, 0.7668, 0.8113)
Macro-average precision, recall, F1: (0.918812, 0.877050, 0.896544)
Item accuracy: 842863 / 871827 (0.9668)
Instance accuracy: 62147 / 87571 (0.7097)

***** Iteration #9 *****
Loss: 9770.856285
Feature norm: 355.616278
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780563, 799490, 790624) (0.9763, 0.9873, 0.9818)
    1: (62276, 72337, 81203) (0.8609, 0.7669, 0.8112)
Macro-average precision, recall, F1: (0.918621, 0.877096, 0.896486)
Item accuracy: 842839 / 871827 (0.9668)
Instance accuracy: 62134 / 87571 (0.7095)

***** Iteration #10 *****
Loss: 9746.160511
Feature norm: 362.566021
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780588, 799500, 790624) (0.9763, 0.9873, 0.9818)
    1: (62291, 72327, 81203) (0.8612, 0.7671, 0.8115)
Macro-average precision, recall, F1: (0.918793, 0.877204, 0.896623)
Item accuracy: 842879 / 871827 (0.9668)
Instance accuracy: 62181 / 87571 (0.7101)

***** Iteration #11 *****
Loss: 9751.830948
Feature norm: 368.958272
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780615, 799535, 790624) (0.9763, 0.9873, 0.9818)
    1: (62283, 72292, 81203) (0.8615, 0.7670, 0.8115)
Macro-average precision, recall, F1: (0.918942, 0.877172, 0.896669)
Item accuracy: 842898 / 871827 (0.9668)
Instance accuracy: 62183 / 87571 (0.7101)

***** Iteration #12 *****
Loss: 9736.685279
Feature norm: 374.967948
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780602, 799490, 790624) (0.9764, 0.9873, 0.9818)
    1: (62315, 72337, 81203) (0.8615, 0.7674, 0.8117)
Macro-average precision, recall, F1: (0.918914, 0.877361, 0.896765)
Item accuracy: 842917 / 871827 (0.9668)
Instance accuracy: 62214 / 87571 (0.7104)

***** Iteration #13 *****
Loss: 9729.624497
Feature norm: 380.609239
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780574, 799485, 790624) (0.9763, 0.9873, 0.9818)
    1: (62292, 72342, 81203) (0.8611, 0.7671, 0.8114)
Macro-average precision, recall, F1: (0.918711, 0.877202, 0.896586)
Item accuracy: 842866 / 871827 (0.9668)
Instance accuracy: 62163 / 87571 (0.7099)

***** Iteration #14 *****
Loss: 9753.543967
Feature norm: 385.844896
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780594, 799492, 790624) (0.9764, 0.9873, 0.9818)
    1: (62305, 72335, 81203) (0.8613, 0.7673, 0.8116)
Macro-average precision, recall, F1: (0.918851, 0.877294, 0.896699)
Item accuracy: 842899 / 871827 (0.9668)
Instance accuracy: 62185 / 87571 (0.7101)

***** Iteration #15 *****
Loss: 9741.781042
Feature norm: 390.744139
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780574, 799464, 790624) (0.9764, 0.9873, 0.9818)
    1: (62313, 72363, 81203) (0.8611, 0.7674, 0.8115)
Macro-average precision, recall, F1: (0.918744, 0.877331, 0.896673)
Item accuracy: 842887 / 871827 (0.9668)
Instance accuracy: 62180 / 87571 (0.7101)

***** Iteration #16 *****
Loss: 9769.811239
Feature norm: 395.308435
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780592, 799475, 790624) (0.9764, 0.9873, 0.9818)
    1: (62320, 72352, 81203) (0.8613, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918863, 0.877385, 0.896756)
Item accuracy: 842912 / 871827 (0.9668)
Instance accuracy: 62209 / 87571 (0.7104)

***** Iteration #17 *****
Loss: 9776.511409
Feature norm: 399.603275
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780591, 799470, 790624) (0.9764, 0.9873, 0.9818)
    1: (62324, 72357, 81203) (0.8613, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918863, 0.877409, 0.896770)
Item accuracy: 842915 / 871827 (0.9668)
Instance accuracy: 62220 / 87571 (0.7105)

***** Iteration #18 *****
Loss: 9724.794615
Feature norm: 403.637494
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780599, 799492, 790624) (0.9764, 0.9873, 0.9818)
    1: (62310, 72335, 81203) (0.8614, 0.7673, 0.8117)
Macro-average precision, recall, F1: (0.918889, 0.877328, 0.896735)
Item accuracy: 842909 / 871827 (0.9668)
Instance accuracy: 62201 / 87571 (0.7103)

***** Iteration #19 *****
Loss: 9750.455398
Feature norm: 407.497532
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780574, 799460, 790624) (0.9764, 0.9873, 0.9818)
    1: (62317, 72367, 81203) (0.8611, 0.7674, 0.8116)
Macro-average precision, recall, F1: (0.918751, 0.877355, 0.896690)
Item accuracy: 842891 / 871827 (0.9668)
Instance accuracy: 62192 / 87571 (0.7102)

***** Iteration #20 *****
Loss: 9751.733560
Feature norm: 411.304493
Seconds required for this iteration: 0.810
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780576, 799466, 790624) (0.9764, 0.9873, 0.9818)
    1: (62313, 72361, 81203) (0.8611, 0.7674, 0.8116)
Macro-average precision, recall, F1: (0.918756, 0.877332, 0.896679)
Item accuracy: 842889 / 871827 (0.9668)
Instance accuracy: 62190 / 87571 (0.7102)

***** Iteration #21 *****
Loss: 9753.184623
Feature norm: 414.983533
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780583, 799469, 790624) (0.9764, 0.9873, 0.9818)
    1: (62317, 72358, 81203) (0.8612, 0.7674, 0.8116)
Macro-average precision, recall, F1: (0.918804, 0.877361, 0.896717)
Item accuracy: 842900 / 871827 (0.9668)
Instance accuracy: 62201 / 87571 (0.7103)

***** Iteration #22 *****
Loss: 9717.472487
Feature norm: 418.422180
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780587, 799474, 790624) (0.9764, 0.9873, 0.9818)
    1: (62316, 72353, 81203) (0.8613, 0.7674, 0.8116)
Macro-average precision, recall, F1: (0.918827, 0.877358, 0.896724)
Item accuracy: 842903 / 871827 (0.9668)
Instance accuracy: 62203 / 87571 (0.7103)

***** Iteration #23 *****
Loss: 9721.358957
Feature norm: 421.718515
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780578, 799460, 790624) (0.9764, 0.9873, 0.9818)
    1: (62321, 72367, 81203) (0.8612, 0.7675, 0.8116)
Macro-average precision, recall, F1: (0.918781, 0.877383, 0.896719)
Item accuracy: 842899 / 871827 (0.9668)
Instance accuracy: 62201 / 87571 (0.7103)

***** Iteration #24 *****
Loss: 9727.208258
Feature norm: 424.906244
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780575, 799445, 790624) (0.9764, 0.9873, 0.9818)
    1: (62333, 72382, 81203) (0.8612, 0.7676, 0.8117)
Macro-average precision, recall, F1: (0.918782, 0.877455, 0.896760)
Item accuracy: 842908 / 871827 (0.9668)
Instance accuracy: 62213 / 87571 (0.7104)

***** Iteration #25 *****
Loss: 9725.847441
Feature norm: 427.942548
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780584, 799463, 790624) (0.9764, 0.9873, 0.9818)
    1: (62324, 72364, 81203) (0.8613, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918821, 0.877405, 0.896749)
Item accuracy: 842908 / 871827 (0.9668)
Instance accuracy: 62207 / 87571 (0.7104)

***** Iteration #26 *****
Loss: 9727.206002
Feature norm: 430.870390
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780560, 799442, 790624) (0.9764, 0.9873, 0.9818)
    1: (62321, 72385, 81203) (0.8610, 0.7675, 0.8115)
Macro-average precision, recall, F1: (0.918673, 0.877371, 0.896665)
Item accuracy: 842881 / 871827 (0.9668)
Instance accuracy: 62188 / 87571 (0.7101)

***** Iteration #27 *****
Loss: 9733.428071
Feature norm: 433.741297
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780572, 799457, 790624) (0.9764, 0.9873, 0.9818)
    1: (62318, 72370, 81203) (0.8611, 0.7674, 0.8116)
Macro-average precision, recall, F1: (0.918740, 0.877360, 0.896688)
Item accuracy: 842890 / 871827 (0.9668)
Instance accuracy: 62198 / 87571 (0.7103)

***** Iteration #28 *****
Loss: 9741.884178
Feature norm: 436.491655
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780577, 799453, 790624) (0.9764, 0.9873, 0.9818)
    1: (62327, 72374, 81203) (0.8612, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918784, 0.877419, 0.896741)
Item accuracy: 842904 / 871827 (0.9668)
Instance accuracy: 62210 / 87571 (0.7104)

***** Iteration #29 *****
Loss: 9752.949496
Feature norm: 439.161934
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780578, 799456, 790624) (0.9764, 0.9873, 0.9818)
    1: (62325, 72371, 81203) (0.8612, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918787, 0.877407, 0.896735)
Item accuracy: 842903 / 871827 (0.9668)
Instance accuracy: 62211 / 87571 (0.7104)

***** Iteration #30 *****
Loss: 9721.800250
Feature norm: 441.744474
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780587, 799468, 790624) (0.9764, 0.9873, 0.9818)
    1: (62322, 72359, 81203) (0.8613, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918836, 0.877394, 0.896749)
Item accuracy: 842909 / 871827 (0.9668)
Instance accuracy: 62223 / 87571 (0.7105)

***** Iteration #31 *****
Loss: 9712.204150
Feature norm: 444.150092
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780594, 799477, 790624) (0.9764, 0.9873, 0.9818)
    1: (62320, 72350, 81203) (0.8614, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918875, 0.877387, 0.896762)
Item accuracy: 842914 / 871827 (0.9668)
Instance accuracy: 62222 / 87571 (0.7105)

***** Iteration #32 *****
Loss: 9737.477145
Feature norm: 446.536792
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780587, 799456, 790624) (0.9764, 0.9873, 0.9818)
    1: (62334, 72371, 81203) (0.8613, 0.7676, 0.8118)
Macro-average precision, recall, F1: (0.918855, 0.877468, 0.896800)
Item accuracy: 842921 / 871827 (0.9668)
Instance accuracy: 62226 / 87571 (0.7106)

***** Iteration #33 *****
Loss: 9709.612541
Feature norm: 448.914092
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780587, 799464, 790624) (0.9764, 0.9873, 0.9818)
    1: (62326, 72363, 81203) (0.8613, 0.7675, 0.8117)
Macro-average precision, recall, F1: (0.918842, 0.877419, 0.896766)
Item accuracy: 842913 / 871827 (0.9668)
Instance accuracy: 62218 / 87571 (0.7105)

***** Iteration #34 *****
Loss: 9773.016744
Feature norm: 451.241764
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780608, 799482, 790624) (0.9764, 0.9873, 0.9818)
    1: (62329, 72345, 81203) (0.8616, 0.7676, 0.8119)
Macro-average precision, recall, F1: (0.918972, 0.877451, 0.896841)
Item accuracy: 842937 / 871827 (0.9669)
Instance accuracy: 62233 / 87571 (0.7107)

***** Iteration #35 *****
Loss: 9717.884773
Feature norm: 453.479712
Seconds required for this iteration: 0.810
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780604, 799488, 790624) (0.9764, 0.9873, 0.9818)
    1: (62319, 72339, 81203) (0.8615, 0.7674, 0.8118)
Macro-average precision, recall, F1: (0.918933, 0.877387, 0.896787)
Item accuracy: 842923 / 871827 (0.9668)
Instance accuracy: 62231 / 87571 (0.7106)

***** Iteration #36 *****
Loss: 9754.372479
Feature norm: 455.659101
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780613, 799469, 790624) (0.9764, 0.9873, 0.9818)
    1: (62347, 72358, 81203) (0.8616, 0.7678, 0.8120)
Macro-average precision, recall, F1: (0.919030, 0.877565, 0.896931)
Item accuracy: 842960 / 871827 (0.9669)
Instance accuracy: 62257 / 87571 (0.7109)

***** Iteration #37 *****
Loss: 9753.543194
Feature norm: 457.818527
Seconds required for this iteration: 0.790
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780596, 799461, 790624) (0.9764, 0.9873, 0.9818)
    1: (62338, 72366, 81203) (0.8614, 0.7677, 0.8119)
Macro-average precision, recall, F1: (0.918915, 0.877499, 0.896843)
Item accuracy: 842934 / 871827 (0.9669)
Instance accuracy: 62237 / 87571 (0.7107)

***** Iteration #38 *****
Loss: 9728.953259
Feature norm: 459.919739
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780587, 799453, 790624) (0.9764, 0.9873, 0.9818)
    1: (62337, 72374, 81203) (0.8613, 0.7677, 0.8118)
Macro-average precision, recall, F1: (0.918859, 0.877487, 0.896812)
Item accuracy: 842924 / 871827 (0.9668)
Instance accuracy: 62231 / 87571 (0.7106)

***** Iteration #39 *****
Loss: 9711.052740
Feature norm: 461.987281
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780585, 799459, 790624) (0.9764, 0.9873, 0.9818)
    1: (62329, 72368, 81203) (0.8613, 0.7676, 0.8117)
Macro-average precision, recall, F1: (0.918835, 0.877436, 0.896773)
Item accuracy: 842914 / 871827 (0.9668)
Instance accuracy: 62222 / 87571 (0.7105)

***** Iteration #40 *****
Loss: 9731.621458
Feature norm: 463.993501
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780595, 799472, 790624) (0.9764, 0.9873, 0.9818)
    1: (62326, 72355, 81203) (0.8614, 0.7675, 0.8118)
Macro-average precision, recall, F1: (0.918890, 0.877424, 0.896790)
Item accuracy: 842921 / 871827 (0.9668)
Instance accuracy: 62224 / 87571 (0.7106)

***** Iteration #41 *****
Loss: 9731.132323
Feature norm: 465.960746
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780594, 799460, 790624) (0.9764, 0.9873, 0.9818)
    1: (62337, 72367, 81203) (0.8614, 0.7677, 0.8118)
Macro-average precision, recall, F1: (0.918901, 0.877491, 0.896833)
Item accuracy: 842931 / 871827 (0.9669)
Instance accuracy: 62233 / 87571 (0.7107)

***** Iteration #42 *****
Loss: 9726.659759
Feature norm: 467.884463
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780592, 799450, 790624) (0.9764, 0.9873, 0.9818)
    1: (62345, 72377, 81203) (0.8614, 0.7678, 0.8119)
Macro-average precision, recall, F1: (0.918902, 0.877539, 0.896860)
Item accuracy: 842937 / 871827 (0.9669)
Instance accuracy: 62238 / 87571 (0.7107)

***** Iteration #43 *****
Loss: 9748.654848
Feature norm: 469.801987
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780594, 799447, 790624) (0.9764, 0.9873, 0.9818)
    1: (62350, 72380, 81203) (0.8614, 0.7678, 0.8119)
Macro-average precision, recall, F1: (0.918922, 0.877571, 0.896887)
Item accuracy: 842944 / 871827 (0.9669)
Instance accuracy: 62244 / 87571 (0.7108)

***** Iteration #44 *****
Loss: 9741.772617
Feature norm: 471.663140
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780592, 799455, 790624) (0.9764, 0.9873, 0.9818)
    1: (62340, 72372, 81203) (0.8614, 0.7677, 0.8119)
Macro-average precision, recall, F1: (0.918894, 0.877508, 0.896839)
Item accuracy: 842932 / 871827 (0.9669)
Instance accuracy: 62233 / 87571 (0.7107)

***** Iteration #45 *****
Loss: 9735.050820
Feature norm: 473.480473
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780599, 799469, 790624) (0.9764, 0.9873, 0.9818)
    1: (62333, 72358, 81203) (0.8615, 0.7676, 0.8118)
Macro-average precision, recall, F1: (0.918925, 0.877470, 0.896831)
Item accuracy: 842932 / 871827 (0.9669)
Instance accuracy: 62234 / 87571 (0.7107)

***** Iteration #46 *****
Loss: 9727.792048
Feature norm: 475.259967
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780610, 799480, 790624) (0.9764, 0.9873, 0.9818)
    1: (62333, 72347, 81203) (0.8616, 0.7676, 0.8119)
Macro-average precision, recall, F1: (0.918990, 0.877477, 0.896864)
Item accuracy: 842943 / 871827 (0.9669)
Instance accuracy: 62242 / 87571 (0.7108)

***** Iteration #47 *****
Loss: 9728.797624
Feature norm: 476.997548
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780609, 799476, 790624) (0.9764, 0.9873, 0.9818)
    1: (62336, 72351, 81203) (0.8616, 0.7677, 0.8119)
Macro-average precision, recall, F1: (0.918989, 0.877495, 0.896873)
Item accuracy: 842945 / 871827 (0.9669)
Instance accuracy: 62242 / 87571 (0.7108)

***** Iteration #48 *****
Loss: 9719.660309
Feature norm: 478.725308
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780614, 799482, 790624) (0.9764, 0.9873, 0.9818)
    1: (62335, 72345, 81203) (0.8616, 0.7676, 0.8119)
Macro-average precision, recall, F1: (0.919017, 0.877492, 0.896884)
Item accuracy: 842949 / 871827 (0.9669)
Instance accuracy: 62243 / 87571 (0.7108)

***** Iteration #49 *****
Loss: 9737.323474
Feature norm: 480.404065
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780613, 799471, 790624) (0.9764, 0.9873, 0.9818)
    1: (62345, 72356, 81203) (0.8616, 0.7678, 0.8120)
Macro-average precision, recall, F1: (0.919027, 0.877553, 0.896923)
Item accuracy: 842958 / 871827 (0.9669)
Instance accuracy: 62251 / 87571 (0.7109)

***** Iteration #50 *****
Loss: 9706.368694
Feature norm: 482.075991
Seconds required for this iteration: 0.800
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (780614, 799474, 790624) (0.9764, 0.9873, 0.9818)
    1: (62343, 72353, 81203) (0.8617, 0.7677, 0.8120)
Macro-average precision, recall, F1: (0.919030, 0.877541, 0.896917)
Item accuracy: 842957 / 871827 (0.9669)
Instance accuracy: 62247 / 87571 (0.7108)

Total seconds required for training: 52.170


End time of the training: 2013-06-12T17:24:16Z

