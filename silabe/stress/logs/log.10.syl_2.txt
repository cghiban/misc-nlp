CRFSuite 0.12  Copyright (c) 2007-2011 Naoaki Okazaki

Start time of the training: 2013-06-11T10:54:04Z

Reading the data set(s)
[1] stress_syl_2.txt
0....1....2....3....4....5....6....7....8....9....10
Number of instances: 262765
Seconds required: 14.470

Statistics the data set(s)
Number of data sets (groups): 3
Number of instances: 262752
Number of items: 2615483
Number of attributes: 3167
Number of labels: 2

===== Cross validation (1/3) =====
Holdout group: 1

Feature generation
type: CRF1d
feature.minfreq: 0.000000
feature.possible_states: 0
feature.possible_transitions: 0
0....1....2....3....4....5....6....7....8....9....10
Number of features: 4377
Seconds required: 2.300

Averaged perceptron
max_iterations: 10
epsilon: 0.000000

***** Iteration #1 *****
Loss: 11415.446008
Feature norm: 210.839229
Seconds required for this iteration: 0.680
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778702, 800760, 790512) (0.9725, 0.9851, 0.9787)
    1: (59115, 70925, 81173) (0.8335, 0.7283, 0.7773)
Macro-average precision, recall, F1: (0.902970, 0.856660, 0.878022)
Item accuracy: 837817 / 871685 (0.9611)
Instance accuracy: 58180 / 87584 (0.6643)

***** Iteration #2 *****
Loss: 11184.191204
Feature norm: 243.637061
Seconds required for this iteration: 0.670
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778620, 800558, 790512) (0.9726, 0.9850, 0.9787)
    1: (59235, 71127, 81173) (0.8328, 0.7297, 0.7779)
Macro-average precision, recall, F1: (0.902701, 0.857347, 0.878305)
Item accuracy: 837855 / 871685 (0.9612)
Instance accuracy: 58263 / 87584 (0.6652)

***** Iteration #3 *****
Loss: 11130.580962
Feature norm: 264.328331
Seconds required for this iteration: 0.670
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778604, 800532, 790512) (0.9726, 0.9849, 0.9787)
    1: (59245, 71153, 81173) (0.8326, 0.7299, 0.7779)
Macro-average precision, recall, F1: (0.902625, 0.857399, 0.878302)
Item accuracy: 837849 / 871685 (0.9612)
Instance accuracy: 58294 / 87584 (0.6656)

***** Iteration #4 *****
Loss: 11125.476539
Feature norm: 278.907881
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778619, 800491, 790512) (0.9727, 0.9850, 0.9788)
    1: (59301, 71194, 81173) (0.8329, 0.7306, 0.7784)
Macro-average precision, recall, F1: (0.902813, 0.857753, 0.878587)
Item accuracy: 837920 / 871685 (0.9613)
Instance accuracy: 58365 / 87584 (0.6664)

***** Iteration #5 *****
Loss: 11106.660707
Feature norm: 290.490542
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778580, 800430, 790512) (0.9727, 0.9849, 0.9788)
    1: (59323, 71255, 81173) (0.8325, 0.7308, 0.7784)
Macro-average precision, recall, F1: (0.902624, 0.857864, 0.878570)
Item accuracy: 837903 / 871685 (0.9612)
Instance accuracy: 58375 / 87584 (0.6665)

***** Iteration #6 *****
Loss: 11093.937699
Feature norm: 300.461907
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778661, 800539, 790512) (0.9727, 0.9850, 0.9788)
    1: (59295, 71146, 81173) (0.8334, 0.7305, 0.7786)
Macro-average precision, recall, F1: (0.903049, 0.857743, 0.878682)
Item accuracy: 837956 / 871685 (0.9613)
Instance accuracy: 58416 / 87584 (0.6670)

***** Iteration #7 *****
Loss: 11096.127500
Feature norm: 308.717017
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778627, 800483, 790512) (0.9727, 0.9850, 0.9788)
    1: (59317, 71202, 81173) (0.8331, 0.7307, 0.7786)
Macro-average precision, recall, F1: (0.902889, 0.857857, 0.878679)
Item accuracy: 837944 / 871685 (0.9613)
Instance accuracy: 58411 / 87584 (0.6669)

***** Iteration #8 *****
Loss: 11104.423292
Feature norm: 315.853327
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778626, 800401, 790512) (0.9728, 0.9850, 0.9788)
    1: (59398, 71284, 81173) (0.8333, 0.7317, 0.7792)
Macro-average precision, recall, F1: (0.903027, 0.858355, 0.879026)
Item accuracy: 838024 / 871685 (0.9614)
Instance accuracy: 58476 / 87584 (0.6677)

***** Iteration #9 *****
Loss: 11098.074671
Feature norm: 321.994965
Seconds required for this iteration: 0.670
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778625, 800410, 790512) (0.9728, 0.9850, 0.9788)
    1: (59388, 71275, 81173) (0.8332, 0.7316, 0.7791)
Macro-average precision, recall, F1: (0.903003, 0.858293, 0.878980)
Item accuracy: 838013 / 871685 (0.9614)
Instance accuracy: 58446 / 87584 (0.6673)

***** Iteration #10 *****
Loss: 11094.301442
Feature norm: 327.625759
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778615, 800389, 790512) (0.9728, 0.9850, 0.9788)
    1: (59399, 71296, 81173) (0.8331, 0.7318, 0.7792)
Macro-average precision, recall, F1: (0.902964, 0.858354, 0.878998)
Item accuracy: 838014 / 871685 (0.9614)
Instance accuracy: 58446 / 87584 (0.6673)

Total seconds required for training: 8.570


===== Cross validation (2/3) =====
Holdout group: 2

Feature generation
type: CRF1d
feature.minfreq: 0.000000
feature.possible_states: 0
feature.possible_transitions: 0
0....1....2....3....4....5....6....7....8....9....10
Number of features: 4339
Seconds required: 2.160

Averaged perceptron
max_iterations: 10
epsilon: 0.000000

***** Iteration #1 *****
Loss: 11449.264889
Feature norm: 209.675673
Seconds required for this iteration: 0.670
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779595, 801434, 791629) (0.9728, 0.9848, 0.9787)
    1: (59458, 71492, 81297) (0.8317, 0.7314, 0.7783)
Macro-average precision, recall, F1: (0.902212, 0.858083, 0.878520)
Item accuracy: 839053 / 872926 (0.9612)
Instance accuracy: 58282 / 87584 (0.6654)

***** Iteration #2 *****
Loss: 11166.129193
Feature norm: 242.444246
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779678, 801519, 791629) (0.9728, 0.9849, 0.9788)
    1: (59456, 71407, 81297) (0.8326, 0.7313, 0.7787)
Macro-average precision, recall, F1: (0.902693, 0.858123, 0.878749)
Item accuracy: 839134 / 872926 (0.9613)
Instance accuracy: 58352 / 87584 (0.6662)

***** Iteration #3 *****
Loss: 11144.060829
Feature norm: 262.495476
Seconds required for this iteration: 0.650
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779610, 801251, 791629) (0.9730, 0.9848, 0.9789)
    1: (59656, 71675, 81297) (0.8323, 0.7338, 0.7800)
Macro-average precision, recall, F1: (0.902652, 0.859310, 0.879414)
Item accuracy: 839266 / 872926 (0.9614)
Instance accuracy: 58477 / 87584 (0.6677)

***** Iteration #4 *****
Loss: 11127.709398
Feature norm: 276.946275
Seconds required for this iteration: 0.650
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779697, 801412, 791629) (0.9729, 0.9849, 0.9789)
    1: (59582, 71514, 81297) (0.8332, 0.7329, 0.7798)
Macro-average precision, recall, F1: (0.903028, 0.858910, 0.879346)
Item accuracy: 839279 / 872926 (0.9615)
Instance accuracy: 58487 / 87584 (0.6678)

***** Iteration #5 *****
Loss: 11133.214638
Feature norm: 288.738973
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779536, 801152, 791629) (0.9730, 0.9847, 0.9788)
    1: (59681, 71774, 81297) (0.8315, 0.7341, 0.7798)
Macro-average precision, recall, F1: (0.902266, 0.859417, 0.879309)
Item accuracy: 839217 / 872926 (0.9614)
Instance accuracy: 58443 / 87584 (0.6673)

***** Iteration #6 *****
Loss: 11107.769878
Feature norm: 298.251771
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779558, 801196, 791629) (0.9730, 0.9848, 0.9788)
    1: (59659, 71730, 81297) (0.8317, 0.7338, 0.7797)
Macro-average precision, recall, F1: (0.902355, 0.859296, 0.879278)
Item accuracy: 839217 / 872926 (0.9614)
Instance accuracy: 58464 / 87584 (0.6675)

***** Iteration #7 *****
Loss: 11116.672426
Feature norm: 306.770023
Seconds required for this iteration: 0.650
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779630, 801360, 791629) (0.9729, 0.9848, 0.9788)
    1: (59567, 71566, 81297) (0.8323, 0.7327, 0.7794)
Macro-average precision, recall, F1: (0.902610, 0.858776, 0.879089)
Item accuracy: 839197 / 872926 (0.9614)
Instance accuracy: 58435 / 87584 (0.6672)

***** Iteration #8 *****
Loss: 11090.334131
Feature norm: 314.040670
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779628, 801379, 791629) (0.9729, 0.9848, 0.9788)
    1: (59546, 71547, 81297) (0.8323, 0.7325, 0.7792)
Macro-average precision, recall, F1: (0.902561, 0.858645, 0.878993)
Item accuracy: 839174 / 872926 (0.9613)
Instance accuracy: 58420 / 87584 (0.6670)

***** Iteration #9 *****
Loss: 11104.840105
Feature norm: 320.730417
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779623, 801371, 791629) (0.9729, 0.9848, 0.9788)
    1: (59549, 71555, 81297) (0.8322, 0.7325, 0.7792)
Macro-average precision, recall, F1: (0.902537, 0.858660, 0.878992)
Item accuracy: 839172 / 872926 (0.9613)
Instance accuracy: 58414 / 87584 (0.6669)

***** Iteration #10 *****
Loss: 11111.761318
Feature norm: 326.685350
Seconds required for this iteration: 0.650
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (779624, 801335, 791629) (0.9729, 0.9848, 0.9788)
    1: (59586, 71591, 81297) (0.8323, 0.7329, 0.7795)
Macro-average precision, recall, F1: (0.902609, 0.858889, 0.879153)
Item accuracy: 839210 / 872926 (0.9614)
Instance accuracy: 58438 / 87584 (0.6672)

Total seconds required for training: 8.490


===== Cross validation (3/3) =====
Holdout group: 3

Feature generation
type: CRF1d
feature.minfreq: 0.000000
feature.possible_states: 0
feature.possible_transitions: 0
0....1....2....3....4....5....6....7....8....9....10
Number of features: 4376
Seconds required: 2.190

Averaged perceptron
max_iterations: 10
epsilon: 0.000000

***** Iteration #1 *****
Loss: 11428.187103
Feature norm: 209.744142
Seconds required for this iteration: 0.670
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777957, 800076, 789621) (0.9724, 0.9852, 0.9787)
    1: (59132, 70796, 81251) (0.8352, 0.7278, 0.7778)
Macro-average precision, recall, F1: (0.903799, 0.856499, 0.878280)
Item accuracy: 837089 / 870872 (0.9612)
Instance accuracy: 58238 / 87584 (0.6649)

***** Iteration #2 *****
Loss: 11220.851688
Feature norm: 241.361915
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777920, 799919, 789621) (0.9725, 0.9852, 0.9788)
    1: (59252, 70953, 81251) (0.8351, 0.7292, 0.7786)
Macro-average precision, recall, F1: (0.903793, 0.857214, 0.878693)
Item accuracy: 837172 / 870872 (0.9613)
Instance accuracy: 58339 / 87584 (0.6661)

***** Iteration #3 *****
Loss: 11179.760773
Feature norm: 260.904611
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777961, 799895, 789621) (0.9726, 0.9852, 0.9789)
    1: (59317, 70977, 81251) (0.8357, 0.7300, 0.7793)
Macro-average precision, recall, F1: (0.904150, 0.857640, 0.879092)
Item accuracy: 837278 / 870872 (0.9614)
Instance accuracy: 58431 / 87584 (0.6671)

***** Iteration #4 *****
Loss: 11162.097343
Feature norm: 275.480748
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777966, 799875, 789621) (0.9726, 0.9852, 0.9789)
    1: (59342, 70997, 81251) (0.8358, 0.7304, 0.7795)
Macro-average precision, recall, F1: (0.904224, 0.857797, 0.879214)
Item accuracy: 837308 / 870872 (0.9615)
Instance accuracy: 58453 / 87584 (0.6674)

***** Iteration #5 *****
Loss: 11174.646880
Feature norm: 286.974941
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778030, 799997, 789621) (0.9725, 0.9853, 0.9789)
    1: (59284, 70875, 81251) (0.8365, 0.7296, 0.7794)
Macro-average precision, recall, F1: (0.904500, 0.857481, 0.879148)
Item accuracy: 837314 / 870872 (0.9615)
Instance accuracy: 58439 / 87584 (0.6672)

***** Iteration #6 *****
Loss: 11138.500979
Feature norm: 296.574418
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777966, 799823, 789621) (0.9727, 0.9852, 0.9789)
    1: (59394, 71049, 81251) (0.8360, 0.7310, 0.7800)
Macro-average precision, recall, F1: (0.904315, 0.858117, 0.879438)
Item accuracy: 837360 / 870872 (0.9615)
Instance accuracy: 58489 / 87584 (0.6678)

***** Iteration #7 *****
Loss: 11139.205275
Feature norm: 304.873142
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777977, 799749, 789621) (0.9728, 0.9853, 0.9790)
    1: (59479, 71123, 81251) (0.8363, 0.7320, 0.7807)
Macro-average precision, recall, F1: (0.904530, 0.858647, 0.879836)
Item accuracy: 837456 / 870872 (0.9616)
Instance accuracy: 58579 / 87584 (0.6688)

***** Iteration #8 *****
Loss: 11165.082668
Feature norm: 312.150946
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777979, 799906, 789621) (0.9726, 0.9853, 0.9789)
    1: (59324, 70966, 81251) (0.8359, 0.7301, 0.7795)
Macro-average precision, recall, F1: (0.904269, 0.857694, 0.879174)
Item accuracy: 837303 / 870872 (0.9615)
Instance accuracy: 58452 / 87584 (0.6674)

***** Iteration #9 *****
Loss: 11124.627361
Feature norm: 318.900146
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (778012, 799929, 789621) (0.9726, 0.9853, 0.9789)
    1: (59334, 70943, 81251) (0.8364, 0.7303, 0.7797)
Macro-average precision, recall, F1: (0.904481, 0.857777, 0.879312)
Item accuracy: 837346 / 870872 (0.9615)
Instance accuracy: 58480 / 87584 (0.6677)

***** Iteration #10 *****
Loss: 11138.544148
Feature norm: 324.976821
Seconds required for this iteration: 0.660
Performance by label (#match, #model, #ref) (precision, recall, F1):
    0: (777990, 799813, 789621) (0.9727, 0.9853, 0.9790)
    1: (59428, 71059, 81251) (0.8363, 0.7314, 0.7804)
Macro-average precision, recall, F1: (0.904517, 0.858341, 0.879654)
Item accuracy: 837418 / 870872 (0.9616)
Instance accuracy: 58573 / 87584 (0.6688)

Total seconds required for training: 8.510


End time of the training: 2013-06-11T10:54:51Z

